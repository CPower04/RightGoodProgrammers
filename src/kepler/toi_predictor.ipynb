{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c5c5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa589068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\downe\\RightGoodProgrammers\\src\\kepler\n",
      "Current Directory: c:\\Users\\downe\\RightGoodProgrammers\\src\\kepler\n",
      "Data Directory: c:\\Users\\downe\\RightGoodProgrammers\\data\n"
     ]
    }
   ],
   "source": [
    "# List files in the data directory to check the correct filename\n",
    "print(os.getcwd())\n",
    "# __file__ is not defined in Jupyter notebooks; use os.getcwd() instead\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "print(\"Current Directory:\", dir_path)\n",
    "dir_path = dir_path.replace('src\\\\kepler', 'data')\n",
    "print(\"Data Directory:\", dir_path)\n",
    "df = pd.read_csv(dir_path + '/processed_toi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37edcb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[['tfopwg_disp_APC', 'tfopwg_disp_CP', 'tfopwg_disp_FA','tfopwg_disp_FP', 'tfopwg_disp_KP', 'tfopwg_disp_PC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4ad63ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (6162, 37) (6162, 6)\n",
      "Testing set shape: (1541, 37) (1541, 6)\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['tfopwg_disp_APC', 'tfopwg_disp_CP', 'tfopwg_disp_FA', 'tfopwg_disp_FP', 'tfopwg_disp_KP', 'tfopwg_disp_PC']\n",
    "x_train = train_df.drop(columns=target_cols)\n",
    "y_train = train_df[target_cols]\n",
    "x_test = test_df.drop(columns=target_cols)\n",
    "y_test = test_df[target_cols]\n",
    "\n",
    "print(\"\\nTraining set shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db590436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix.png\n",
      "k2panda_model.pkl\n",
      "keplerkepler_rf_best.pkl\n",
      "toiscaler.joblib\n",
      "Before scaling:\n",
      "Mean: 43163.25\n",
      "Std: 24867.81\n",
      "\n",
      "After scaling:\n",
      "Mean: 0.00\n",
      "Std: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize scaler if it doesnt exist\n",
    "for file in os.listdir(dir_path.replace('data', 'models')):\n",
    "    print(file)\n",
    "    if 'toiscaler' in file:\n",
    "        scaler = joblib.load(os.path.join(dir_path.replace('data', 'models'), file))\n",
    "        break\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform training data (learns mean and std)\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# Transform test data (using training mean/std)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Convert back to DataFrames to keep column names\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_train.columns, index=x_train.index)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_test.columns, index=x_test.index)\n",
    "\n",
    "# Show before/after scaling for first feature\n",
    "print(\"Before scaling:\")\n",
    "print(f\"Mean: {x_train.iloc[:,0].mean():.2f}\")\n",
    "print(f\"Std: {x_train.iloc[:,0].std():.2f}\")\n",
    "\n",
    "print(\"\\nAfter scaling:\")\n",
    "print(f\"Mean: {x_train_scaled.iloc[:,0].mean():.2f}\")\n",
    "print(f\"Std: {x_train_scaled.iloc[:,0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "186f08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes: ['APC' 'CP' 'FA' 'FP' 'KP' 'PC']\n",
      "Training Label Distribution: 5    3743\n",
      "3     958\n",
      "1     547\n",
      "4     466\n",
      "0     370\n",
      "2      78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: [0 1 2 3 4 5]\n",
      "Training Label Distribution: 5    3743\n",
      "3     958\n",
      "1     547\n",
      "4     466\n",
      "0     370\n",
      "2      78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: [0 1 2 3 4 5]\n",
      "Training Label Distribution: 5    3743\n",
      "3     958\n",
      "1     547\n",
      "4     466\n",
      "0     370\n",
      "2      78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classes: [0 1 2 3 4 5]\n",
      "Training Label Distribution: 5    3743\n",
      "3     958\n",
      "1     547\n",
      "4     466\n",
      "0     370\n",
      "2      78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.idxmax(axis=1).str.replace('tfopwg_disp_', '').str.strip()\n",
    "y_test = y_test.idxmax(axis=1).str.replace('tfopwg_disp_', '').str.strip()\n",
    "\n",
    "\n",
    "for file in os.listdir(dir_path.replace('data', 'models')):\n",
    "    if 'toilabelencoder' in file:\n",
    "        label_encoder = joblib.load(os.path.join(dir_path.replace('data', 'models'), file))\n",
    "        break\n",
    "    else:\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        y_train = label_encoder.fit_transform(y_train)\n",
    "        y_test = label_encoder.transform(y_test)\n",
    "\n",
    "        print(\"\\nClasses:\", label_encoder.classes_)\n",
    "        print(\"Training Label Distribution:\",pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e513ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest with 20 trees...\n",
      "F1 Score: 0.6541\n",
      "New best model found!\n",
      "\n",
      "Training Random Forest with 54 trees...\n",
      "F1 Score: 0.6588\n",
      "New best model found!\n",
      "\n",
      "Training Random Forest with 89 trees...\n",
      "F1 Score: 0.6569\n",
      "\n",
      "Training Random Forest with 123 trees...\n",
      "F1 Score: 0.6528\n",
      "\n",
      "Training Random Forest with 158 trees...\n",
      "F1 Score: 0.6586\n",
      "\n",
      "Training Random Forest with 192 trees...\n",
      "F1 Score: 0.6528\n",
      "\n",
      "Training Random Forest with 227 trees...\n",
      "F1 Score: 0.6552\n",
      "\n",
      "Training Random Forest with 261 trees...\n",
      "F1 Score: 0.6573\n",
      "\n",
      "Training Random Forest with 296 trees...\n",
      "F1 Score: 0.6541\n",
      "\n",
      "Training Random Forest with 330 trees...\n",
      "F1 Score: 0.6565\n",
      "\n",
      "Training Random Forest with 365 trees...\n",
      "F1 Score: 0.6547\n",
      "\n",
      "Training Random Forest with 400 trees...\n",
      "F1 Score: 0.6539\n"
     ]
    }
   ],
   "source": [
    "number_of_trees = [int(x) for x in np.linspace(start = 20, stop = 400, num = 12)]\n",
    "best_f1 = 0\n",
    "best_rf = None\n",
    "for file in os.listdir(dir_path.replace('data', 'models')):\n",
    "    if 'toirandomforest' in file:\n",
    "        best_rf = joblib.load(os.path.join(dir_path.replace('data', 'models'), file))\n",
    "        y_pred = best_rf.predict(x_test_scaled)\n",
    "        best_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f\"Loaded existing model with F1 Score: {best_f1:.4f}\")\n",
    "        break\n",
    "    \n",
    "for n_trees in number_of_trees:\n",
    "    print(f\"\\nTraining Random Forest with {n_trees} trees...\")\n",
    "    rf = RandomForestClassifier(n_estimators=n_trees, random_state=42, n_jobs=-1)\n",
    "    rf.fit(x_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(x_test_scaled)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_rf = rf\n",
    "        print(\"New best model found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "11f518ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 69.95%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Prediction Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c923ebb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\downe\\\\RightGoodProgrammers\\\\models\\\\toi_rf_best.pkl']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "model_dir = current_dir.replace('src\\\\kepler', 'models\\\\')\n",
    "joblib.dump(best_rf, model_dir + 'toi_rf_best.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
