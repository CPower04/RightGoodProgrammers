{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97b43cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa73a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      kepid kepoi_name   kepler_name koi_disposition koi_pdisposition  \\\n",
      "0  10797460  K00752.01  Kepler-227 b       CONFIRMED        CANDIDATE   \n",
      "\n",
      "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  \\\n",
      "0        1.0              0              0              0              0  ...   \n",
      "\n",
      "   koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
      "0           -81.0      4.467           0.064          -0.096     0.927   \n",
      "\n",
      "   koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
      "0          0.105         -0.061  291.93423  48.141651      15.347  \n",
      "\n",
      "[1 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "##open and read the csv files into pandas dataframes\n",
    "dir = os.getcwd()\n",
    "dir_path = dir.replace('src\\kepler', 'data\\\\')\n",
    "with  open(dir_path + 'cumulative_2025.10.03_13.30.13.csv') as cumulative:\n",
    "    cumulative_df = pd.read_csv(cumulative)\n",
    "    print(cumulative_df.head(1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c523fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop unnecessary columns\n",
    "# Drop only the columns you don’t want as features\n",
    "cumulative_df = cumulative_df.drop(columns=[\n",
    "    'kepid',            # we don't need this ID column\n",
    "    'kepoi_name',       # we don't need this KOI name column\n",
    "    'kepler_name',      # we don't need the official Kepler name column\n",
    "    'koi_pdisposition', # we don't need the predicted disposition column\n",
    "    'koi_tce_delivname',# we don't need the delivery file name column\n",
    "    'ra',               # we don't need right ascension (sky coordinate)\n",
    "    'dec',              # we don't need declination (sky coordinate)\n",
    "    'koi_tce_plnt_num'  # we don't need the number of planets per TCE\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0a6d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop columns that have more than 75 percent missing values\n",
    "threshold = int(np.ceil(len(cumulative_df) * 0.75))  # require ≥75% non-missing to keep\n",
    "cumulative_df = cumulative_df.dropna(thresh=threshold, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e37e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'koi_disposition' has 0 null values (0.00%).\n",
      "Column 'koi_score' has 1510 null values (15.79%).\n",
      "Column 'koi_fpflag_nt' has 0 null values (0.00%).\n",
      "Column 'koi_fpflag_ss' has 0 null values (0.00%).\n",
      "Column 'koi_fpflag_co' has 0 null values (0.00%).\n",
      "Column 'koi_fpflag_ec' has 0 null values (0.00%).\n",
      "Column 'koi_period' has 0 null values (0.00%).\n",
      "Column 'koi_period_err1' has 454 null values (4.75%).\n",
      "Column 'koi_period_err2' has 454 null values (4.75%).\n",
      "Column 'koi_time0bk' has 0 null values (0.00%).\n",
      "Column 'koi_time0bk_err1' has 454 null values (4.75%).\n",
      "Column 'koi_time0bk_err2' has 454 null values (4.75%).\n",
      "Column 'koi_impact' has 363 null values (3.80%).\n",
      "Column 'koi_impact_err1' has 454 null values (4.75%).\n",
      "Column 'koi_impact_err2' has 454 null values (4.75%).\n",
      "Column 'koi_duration' has 0 null values (0.00%).\n",
      "Column 'koi_duration_err1' has 454 null values (4.75%).\n",
      "Column 'koi_duration_err2' has 454 null values (4.75%).\n",
      "Column 'koi_depth' has 363 null values (3.80%).\n",
      "Column 'koi_depth_err1' has 454 null values (4.75%).\n",
      "Column 'koi_depth_err2' has 454 null values (4.75%).\n",
      "Column 'koi_prad' has 363 null values (3.80%).\n",
      "Column 'koi_prad_err1' has 363 null values (3.80%).\n",
      "Column 'koi_prad_err2' has 363 null values (3.80%).\n",
      "Column 'koi_teq' has 363 null values (3.80%).\n",
      "Column 'koi_insol' has 321 null values (3.36%).\n",
      "Column 'koi_insol_err1' has 321 null values (3.36%).\n",
      "Column 'koi_insol_err2' has 321 null values (3.36%).\n",
      "Column 'koi_model_snr' has 363 null values (3.80%).\n",
      "Column 'koi_steff' has 363 null values (3.80%).\n",
      "Column 'koi_steff_err1' has 468 null values (4.89%).\n",
      "Column 'koi_steff_err2' has 483 null values (5.05%).\n",
      "Column 'koi_slogg' has 363 null values (3.80%).\n",
      "Column 'koi_slogg_err1' has 468 null values (4.89%).\n",
      "Column 'koi_slogg_err2' has 468 null values (4.89%).\n",
      "Column 'koi_srad' has 363 null values (3.80%).\n",
      "Column 'koi_srad_err1' has 468 null values (4.89%).\n",
      "Column 'koi_srad_err2' has 468 null values (4.89%).\n",
      "Column 'koi_kepmag' has 1 null values (0.01%).\n"
     ]
    }
   ],
   "source": [
    "##count nulls in each column as a percentage of total rows\n",
    "for col in cumulative_df.columns:\n",
    "    null_count = cumulative_df[col].isnull().sum()\n",
    "    null_percentage = (null_count / len(cumulative_df)) * 100\n",
    "    print(f\"Column '{col}' has {null_count} null values ({null_percentage:.2f}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "955877c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of encoded DataFrame: (9564, 41)\n",
      "\n",
      "Columns in encoded DataFrame: ['koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2', 'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'koi_kepmag', 'koi_disposition_CANDIDATE', 'koi_disposition_CONFIRMED', 'koi_disposition_FALSE POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical_columns = cumulative_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "\n",
    "# Perform one-hot encoding with NaN handling\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fill NaN values with 'missing' before encoding\n",
    "cat_data = cumulative_df[categorical_columns].fillna('missing')\n",
    "one_hot_encoded = encoder.fit_transform(cat_data)\n",
    "##C:\\Users\\downe\\RightGoodProgrammers\\src\\kepler\\cumulative.ipynb\n",
    "# Create DataFrame with encoded columns\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "one_hot_df = pd.DataFrame(\n",
    "    one_hot_encoded, \n",
    "    columns=feature_names,\n",
    "    index=cumulative_df.index\n",
    ")\n",
    "\n",
    "# Get numeric columns to keep\n",
    "numeric_columns = cumulative_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Combine numeric and encoded categorical columns\n",
    "df_encoded = pd.concat([\n",
    "    cumulative_df[numeric_columns],  # Keep numeric columns\n",
    "    one_hot_df  # Add encoded categorical columns\n",
    "], axis=1)\n",
    "\n",
    "print(\"\\nShape of encoded DataFrame:\", df_encoded.shape)\n",
    "print(\"\\nColumns in encoded DataFrame:\", df_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b092c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of feature matrix X: (9564, 38)\n",
      "\n",
      "Shape of target matrix y: (9564, 3)\n"
     ]
    }
   ],
   "source": [
    "y = df_encoded[['koi_disposition_CANDIDATE', 'koi_disposition_CONFIRMED', 'koi_disposition_FALSE POSITIVE']]\n",
    "X = df_encoded.drop(columns=[\n",
    "    'koi_disposition_CANDIDATE', \n",
    "    'koi_disposition_CONFIRMED', \n",
    "    'koi_disposition_FALSE POSITIVE'\n",
    "])\n",
    "print(\"\\nShape of feature matrix X:\", X.shape)\n",
    "print(\"\\nShape of target matrix y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12ad7bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped columns due to high correlation: ['koi_period_err2', 'koi_time0bk_err2', 'koi_impact_err2', 'koi_duration_err2', 'koi_depth_err2', 'koi_prad_err1', 'koi_prad_err2', 'koi_insol_err1', 'koi_insol_err2', 'koi_steff_err2', 'koi_srad_err1', 'koi_srad_err2']\n"
     ]
    }
   ],
   "source": [
    "##find correlated features in x and drop them\n",
    "corr_matrix = X.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.7)]\n",
    "X = X.drop(columns=to_drop)\n",
    "print(\"\\nDropped columns due to high correlation:\", to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34966f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.concat([X, y], axis=1)\n",
    "dir = os.getcwd()\n",
    "dir_path = dir.replace('src\\kepler', 'data\\\\')\n",
    "dataframe.to_csv(dir_path + 'cumulative_final_2025.10.03.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
