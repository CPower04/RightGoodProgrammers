{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ffa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0565d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\downe\\RightGoodProgrammers\\src\\kepler\n",
      "Current Directory: c:\\Users\\downe\\RightGoodProgrammers\\src\\kepler\n",
      "Data Directory: c:\\Users\\downe\\RightGoodProgrammers\\data\n"
     ]
    }
   ],
   "source": [
    "# List files in the data directory to check the correct filename\n",
    "print(os.getcwd())\n",
    "# __file__ is not defined in Jupyter notebooks; use os.getcwd() instead\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "print(\"Current Directory:\", dir_path)\n",
    "dir_path = dir_path.replace('src\\\\kepler', 'data')\n",
    "print(\"Data Directory:\", dir_path)\n",
    "df = pd.read_csv(dir_path + '/cumulative_final_2025.10.03.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##perform a train test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[['koi_disposition_CANDIDATE', 'koi_disposition_CONFIRMED', 'koi_disposition_FALSE POSITIVE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ba421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes: (7651, 32) (7651, 3)\n",
      "Testing shapes: (1913, 32) (1913, 3)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "target_cols = ['koi_disposition_CANDIDATE', 'koi_disposition_CONFIRMED', 'koi_disposition_FALSE POSITIVE']\n",
    "X_train = train_df.drop(columns=target_cols)\n",
    "y_train = train_df[target_cols]\n",
    "X_test = test_df.drop(columns=target_cols)\n",
    "y_test = test_df[target_cols]\n",
    "\n",
    "# Print shapes to verify split\n",
    "print(\"Training shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aac6b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keplerkepler_rf_best.joblib\n",
      "keplerlabel_encoder.joblib\n",
      "keplerscaler.joblib\n",
      "Before scaling:\n",
      "Mean: 0.48\n",
      "Std: 0.48\n",
      "\n",
      "After scaling:\n",
      "Mean: -0.00\n",
      "Std: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize scaler if it doesnt exist\n",
    "for file in os.listdir(dir_path.replace('data', 'models')):\n",
    "    print(file)\n",
    "    if 'keplerscaler' in file:\n",
    "        scaler = joblib.load(os.path.join(dir_path.replace('data', 'models'), file))\n",
    "        break\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform training data (learns mean and std)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data (using training mean/std)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrames to keep column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Show before/after scaling for first feature\n",
    "print(\"Before scaling:\")\n",
    "print(f\"Mean: {X_train.iloc[:,0].mean():.2f}\")\n",
    "print(f\"Std: {X_train.iloc[:,0].std():.2f}\")\n",
    "\n",
    "print(\"\\nAfter scaling:\")\n",
    "print(f\"Mean: {X_train_scaled.iloc[:,0].mean():.2f}\")\n",
    "print(f\"Std: {X_train_scaled.iloc[:,0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ed4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['CANDIDATE' 'CONFIRMED' 'FALSE POSITIVE']\n",
      "Training label distribution:\n",
      " 2    3871\n",
      "1    2197\n",
      "0    1583\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert one-hot DataFrame -> single string label -> integer codes\n",
    "y_train_single = y_train.idxmax(axis=1).str.replace('koi_disposition_', '').str.strip()\n",
    "y_test_single  = y_test.idxmax(axis=1).str.replace('koi_disposition_', '').str.strip()\n",
    "##encode labels\n",
    "for filename in os.listdir(dir_path.replace('data', 'models')):\n",
    "    if 'label_encoder.joblib' in filename:\n",
    "        le = joblib.load(dir_path.replace('data', 'models') + '//' + filename)\n",
    "        break\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "y_train_enc = le.fit_transform(y_train_single)\n",
    "y_test_enc  = le.transform(y_test_single)\n",
    "\n",
    "print(\"Classes:\", le.classes_)\n",
    "print(\"Training label distribution:\\n\", pd.Series(y_train_enc).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "715a4601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model with F1 score: 0.9246\n",
      "Best F1 score: 0.9246\n"
     ]
    }
   ],
   "source": [
    "# create a RandomForestClassifier and save the best model based on f1 score\n",
    "number_of_trees = [100, 200, 300, 400, 500]\n",
    "best_f1 = 0\n",
    "best_rf = None\n",
    "for filename in os.listdir(dir_path.replace('data', 'models')):\n",
    "    if 'kepler_rf_best.joblib' in filename:\n",
    "        best_rf = joblib.load(dir_path.replace('data', 'models') + '//' + filename)\n",
    "        y_pred = best_rf.predict(X_test_scaled)\n",
    "        best_f1 = f1_score(y_test_enc, y_pred, average='weighted')\n",
    "        print(f\"Loaded existing model with F1 score: {best_f1:.4f}\")\n",
    "        break\n",
    "    else:\n",
    "        for n in number_of_trees:\n",
    "            rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "            rf.fit(X_train_scaled, y_train_enc)\n",
    "            y_pred = rf.predict(X_test_scaled)\n",
    "            f1 = f1_score(y_test_enc, y_pred, average='weighted')\n",
    "            print(f\"F1 score for {n} trees: {f1:.4f}\")\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_rf = rf\n",
    "\n",
    "print(f\"Best F1 score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acf17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     CANDIDATE       0.85      0.79      0.82       396\n",
      "     CONFIRMED       0.87      0.91      0.89       549\n",
      "FALSE POSITIVE       0.98      0.99      0.99       968\n",
      "\n",
      "      accuracy                           0.93      1913\n",
      "     macro avg       0.90      0.90      0.90      1913\n",
      "  weighted avg       0.92      0.93      0.92      1913\n",
      "\n",
      "Confusion matrix:\n",
      "[[313  71  12]\n",
      " [ 44 501   4]\n",
      " [ 10   2 956]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test_enc, y_pred, target_names=le.classes_))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ee415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\downe\\\\RightGoodProgrammers\\\\models\\\\keplerscaler.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save best model and label encoder and scaler\n",
    "current_dir = os.getcwd()\n",
    "model_dir = current_dir.replace('src\\\\kepler', 'models\\\\kepler')\n",
    "joblib.dump(best_rf, model_dir + 'kepler_rf_best.joblib')\n",
    "joblib.dump(le, model_dir + 'label_encoder.joblib')\n",
    "joblib.dump(scaler, model_dir + 'scaler.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
